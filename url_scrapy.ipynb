{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "url_scrapy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxeBwW-m7BHH"
      },
      "source": [
        "import requests,re\n",
        "from urllib import parse\n",
        "from time import sleep,time\n",
        " \n",
        "'''URL采集器Author:h4ckg3h2y1'''\n",
        " \n",
        "header = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0'}\n",
        " \n",
        "def google(keyword,pagenumber):\n",
        "    time_stamp = str(time())\n",
        "    try:\n",
        "        for page in range(0,(pagenumber-1)*10+1,10):\n",
        "            google_url = 'https://www.google.com/search?q={}&start={}'.format(keyword,page)\n",
        "            html = requests.get(google_url)\n",
        "            patt = re.compile('\"><a href=\"/url\\?q=(.*?)&amp;sa=')\n",
        "            url_list = re.findall(patt,html.text)\n",
        "            ext(url_list,time_stamp)\n",
        "            sleep(5)\n",
        "    except requests.exceptions.ProxyError:\n",
        "        print('请求被拦截，可能需要进行人机验证')\n",
        " \n",
        "def baidu(keyword,pagenumber):\n",
        "    time_stamp = str(time())\n",
        "    try:\n",
        "        for page in range(0,(pagenumber-1)*10+1,10):\n",
        "            baidu_url = 'https://www.baidu.com/s?wd={}&pn={}'.format(keyword,page)\n",
        "            html = requests.get(baidu_url,headers=header)\n",
        "            patt = re.compile('\"><a target=\"_blank\" href=\"(.*?)\" class=\"')\n",
        "            url_list = re.findall(patt,html.text)\n",
        "            baidu_ext(url_list,time_stamp)\n",
        "            sleep(5)\n",
        "    except requests.exceptions.ProxyError:\n",
        "        print('请求被拦截，可能需要进行人机验证')\n",
        " \n",
        "def bing(keyword,pagenumber):\n",
        "    time_stamp = str(time())\n",
        "    try:\n",
        "        for page in range(1,pagenumber*10+1,10):\n",
        "            bing_url = 'https://cn.bing.com/search?q={}&go=%e6%90%9c%e7%b4%a2&qs=ds&mkt=zh-CN&first={}&FORM=PERE'.format(keyword,page)\n",
        "            html = requests.get(bing_url,headers=header)\n",
        "            patt = re.compile('<a target=\"_blank\" href=\"(.*?)\" h=')\n",
        "            url_list = re.findall(patt,html.text)\n",
        "            ext(url_list,time_stamp)\n",
        "            sleep(5)\n",
        "    except requests.exceptions.ProxyError:\n",
        "        print('请求被拦截，可能需要进行人机验证')\n",
        " \n",
        "def ext(url_list,time_stamp):\n",
        "    try:\n",
        "        for url in url_list:\n",
        "            url = parse.unquote(url)\n",
        "            with open('{}.txt'.format(time_stamp),'a') as f:\n",
        "                f.write(url+'\\n')\n",
        "                print('[+]'+url)\n",
        "    except:\n",
        "        print('请求超时')\n",
        " \n",
        "#百度采集的URL需要经过二次访问才能获得原ip\n",
        "def baidu_ext(url_list,time_stamp):\n",
        "    try:\n",
        "        for url in url_list:\n",
        "            again = requests.get(url,headers=header,timeout=5.0)\n",
        "            with open('{}.txt'.format(time_stamp),'a') as f:\n",
        "                f.write(again.url+'\\n')\n",
        "                print('[+]'+again.url)\n",
        "                sleep(1)\n",
        "    except:\n",
        "        print('请求超时')\n",
        " \n",
        "def main(Search_engine,Search_key,Search_page):\n",
        "    if Search_engine == 1:\n",
        "        google(Search_key,Search_page)\n",
        "    elif Search_engine == 2:\n",
        "        bing(Search_key,Search_page)\n",
        "    elif Search_engine == 3:\n",
        "        baidu(Search_key,Search_page)\n",
        "    else:\n",
        "        print('请输入正确的编号')\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print('''Instructions：URL采集，请求超时可能是触发了搜索引擎的人机验证。''')\n",
        "    Search_engine = input('请输入调用的搜索引擎编号[1 : Google][2 : Bing][3 : BaiDu]: ')\n",
        "    Search_key = input('请输入关键词: ')\n",
        "    Search_page = input('请输采集页数(10条/1页): ')\n",
        "    main(int(Search_engine),Search_key,int(Search_page))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Lg-mHX7B8W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}